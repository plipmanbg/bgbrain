{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pefile\n",
    "import os\n",
    "import array\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "import sys\n",
    "import argparse\n",
    "from flask import Flask, request, render_template\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('upload.html')\n",
    "\n",
    "@app.route('/uploader',methods=['POST'])\n",
    "def upload_file():\n",
    "\n",
    "    f = request.files['file']\n",
    "    \n",
    "    # Load classifier\n",
    "    \n",
    "    clf = joblib.load(os.path.join(\n",
    "        os.path.dirname(os.path.realpath(__file__)),\n",
    "        'classifier.pkl'\n",
    "    ))\n",
    "    \n",
    "    features = pickle.loads(open(os.path.join(\n",
    "        os.path.dirname(os.path.realpath(__file__)),\n",
    "        'features.pkl'),\n",
    "        'rb').read()\n",
    "    )\n",
    "\n",
    "    \n",
    "    data = pefile_features(f.filename)\n",
    "\n",
    "    pe_features = list(map(lambda x:data[x], features))\n",
    "\n",
    "    t0 = time.clock()\n",
    "\n",
    "    res= clf.predict([pe_features])[0]\n",
    "    p_clean = clf.predict_proba([pe_features])[0][0]\n",
    "    p_malicious = clf.predict_proba([pe_features])[0][1]\n",
    "    \n",
    "    t1 = time.clock()\n",
    "    \n",
    "    elapsed_ms = np.around(1000*(t1 - t0), decimals=2)\n",
    "\n",
    "    p_clean_rd = np.around(100 * p_clean,decimals=2)\n",
    "    p_malicious_rd = np.around(100 * p_malicious,decimals=2)\n",
    "    \n",
    "    return render_template('result.html', name=f.filename, prediction=res,\n",
    "                           time = elapsed_ms, clean_prob = p_clean_rd, malicious_prob = p_malicious_rd)\n",
    "\n",
    "def get_entropy(data):\n",
    "    if len(data) == 0:\n",
    "        return 0.0\n",
    "    occurences = array.array('L', [0]*256)\n",
    "    for x in data:\n",
    "        occurences[x if isinstance(x, int) else ord(x)] += 1\n",
    "    entropy = 0\n",
    "    for x in occurences:\n",
    "        if x:\n",
    "            p_x = float(x) / len(data)\n",
    "            entropy -= p_x*math.log(p_x, 2)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def get_resources(pe):\n",
    "    resources = []\n",
    "    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):\n",
    "        try:\n",
    "            for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n",
    "                if hasattr(resource_type, 'directory'):\n",
    "                    for resource_id in resource_type.directory.entries:\n",
    "                        if hasattr(resource_id, 'directory'):\n",
    "                            for resource_lang in resource_id.directory.entries:\n",
    "                                data = pe.get_data(resource_lang.data.struct.OffsetToData, resource_lang.data.struct.Size)\n",
    "                                size = resource_lang.data.struct.Size\n",
    "                                entropy = get_entropy(data)\n",
    "\n",
    "                                resources.append([entropy, size])\n",
    "        except Exception as e:\n",
    "            return resources\n",
    "    return resources\n",
    "\n",
    "def get_version_info(pe):\n",
    "    res = {}\n",
    "    for fileinfo in pe.FileInfo:\n",
    "        if fileinfo.Key == 'StringFileInfo':\n",
    "            for st in fileinfo.StringTable:\n",
    "                for entry in st.entries.items():\n",
    "                    res[entry[0]] = entry[1]\n",
    "        if fileinfo.Key == 'VarFileInfo':\n",
    "            for var in fileinfo.Var:\n",
    "                res[var.entry.items()[0][0]] = var.entry.items()[0][1]\n",
    "    if hasattr(pe, 'VS_FIXEDFILEINFO'):\n",
    "          res['flags'] = pe.VS_FIXEDFILEINFO.FileFlags\n",
    "          res['os'] = pe.VS_FIXEDFILEINFO.FileOS\n",
    "          res['type'] = pe.VS_FIXEDFILEINFO.FileType\n",
    "          res['file_version'] = pe.VS_FIXEDFILEINFO.FileVersionLS\n",
    "          res['product_version'] = pe.VS_FIXEDFILEINFO.ProductVersionLS\n",
    "          res['signature'] = pe.VS_FIXEDFILEINFO.Signature\n",
    "          res['struct_version'] = pe.VS_FIXEDFILEINFO.StrucVersion\n",
    "    return res\n",
    "\n",
    "def pefile_features(fpath):\n",
    "    res = {}\n",
    "    pe = pefile.PE(fpath)\n",
    "    res['Machine'] = pe.FILE_HEADER.Machine\n",
    "    res['SizeOfOptionalHeader'] = pe.FILE_HEADER.SizeOfOptionalHeader\n",
    "    res['Characteristics'] = pe.FILE_HEADER.Characteristics\n",
    "    res['MajorLinkerVersion'] = pe.OPTIONAL_HEADER.MajorLinkerVersion\n",
    "    res['MinorLinkerVersion'] = pe.OPTIONAL_HEADER.MinorLinkerVersion\n",
    "    res['SizeOfCode'] = pe.OPTIONAL_HEADER.SizeOfCode\n",
    "    res['SizeOfInitializedData'] = pe.OPTIONAL_HEADER.SizeOfInitializedData\n",
    "    res['SizeOfUninitializedData'] = pe.OPTIONAL_HEADER.SizeOfUninitializedData\n",
    "    res['AddressOfEntryPoint'] = pe.OPTIONAL_HEADER.AddressOfEntryPoint\n",
    "    res['BaseOfCode'] = pe.OPTIONAL_HEADER.BaseOfCode\n",
    "    try:\n",
    "        res['BaseOfData'] = pe.OPTIONAL_HEADER.BaseOfData\n",
    "    except AttributeError:\n",
    "        res['BaseOfData'] = 0\n",
    "    res['ImageBase'] = pe.OPTIONAL_HEADER.ImageBase\n",
    "    res['SectionAlignment'] = pe.OPTIONAL_HEADER.SectionAlignment\n",
    "    res['FileAlignment'] = pe.OPTIONAL_HEADER.FileAlignment\n",
    "    res['MajorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion\n",
    "    res['MinorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MinorOperatingSystemVersion\n",
    "    res['MajorImageVersion'] = pe.OPTIONAL_HEADER.MajorImageVersion\n",
    "    res['MinorImageVersion'] = pe.OPTIONAL_HEADER.MinorImageVersion\n",
    "    res['MajorSubsystemVersion'] = pe.OPTIONAL_HEADER.MajorSubsystemVersion\n",
    "    res['MinorSubsystemVersion'] = pe.OPTIONAL_HEADER.MinorSubsystemVersion\n",
    "    res['SizeOfImage'] = pe.OPTIONAL_HEADER.SizeOfImage\n",
    "    res['SizeOfHeaders'] = pe.OPTIONAL_HEADER.SizeOfHeaders\n",
    "    res['CheckSum'] = pe.OPTIONAL_HEADER.CheckSum\n",
    "    res['Subsystem'] = pe.OPTIONAL_HEADER.Subsystem\n",
    "    res['DllCharacteristics'] = pe.OPTIONAL_HEADER.DllCharacteristics\n",
    "    res['SizeOfStackReserve'] = pe.OPTIONAL_HEADER.SizeOfStackReserve\n",
    "    res['SizeOfStackCommit'] = pe.OPTIONAL_HEADER.SizeOfStackCommit\n",
    "    res['SizeOfHeapReserve'] = pe.OPTIONAL_HEADER.SizeOfHeapReserve\n",
    "    res['SizeOfHeapCommit'] = pe.OPTIONAL_HEADER.SizeOfHeapCommit\n",
    "    res['LoaderFlags'] = pe.OPTIONAL_HEADER.LoaderFlags\n",
    "    res['NumberOfRvaAndSizes'] = pe.OPTIONAL_HEADER.NumberOfRvaAndSizes\n",
    "    res['SectionsNb'] = len(pe.sections) # Number of sections in PE file\n",
    "    \n",
    "    entropy = map(lambda x:x.get_entropy(), pe.sections)\n",
    "    entropy_list = list(entropy)\n",
    "    res['SectionsMeanEntropy'] = sum(entropy)/float(len(entropy_list))\n",
    "    res['SectionsMinEntropy'] = min(entropy_list)\n",
    "    res['SectionsMaxEntropy'] = max(entropy_list)\n",
    "    \n",
    "    raw_sizes = map(lambda x:x.SizeOfRawData, pe.sections)\n",
    "    raw_sizes_list = list(raw_sizes)\n",
    "    res['SectionsMeanRawsize'] = sum(raw_sizes)/float(len(raw_sizes_list))\n",
    "    res['SectionsMinRawsize'] = min(raw_sizes_list)\n",
    "    res['SectionMaxRawsize'] = max(raw_sizes_list)\n",
    "    \n",
    "    virtual_sizes = map(lambda x:x.Misc_VirtualSize, pe.sections)\n",
    "    virtual_sizes_list = list(virtual_sizes)\n",
    "    res['SectionsMeanVirtualsize'] = sum(virtual_sizes)/float(len(virtual_sizes_list))\n",
    "    res['SectionsMinVirtualsize'] = min(virtual_sizes_list)\n",
    "    res['SectionMaxVirtualsize'] = max(virtual_sizes_list)\n",
    "\n",
    "    #Imports\n",
    "    try:\n",
    "        res['ImportsNbDLL'] = len(pe.DIRECTORY_ENTRY_IMPORT)\n",
    "        imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])\n",
    "        res['ImportsNb'] = len(imports)\n",
    "        clean_imports = filter(lambda x:x.name is None, imports)\n",
    "        res['ImportsNbOrdinal'] = len(list(clean_imports))\n",
    "    except AttributeError:\n",
    "        res['ImportsNbDLL'] = 0\n",
    "        res['ImportsNb'] = 0\n",
    "        res['ImportsNbOrdinal'] = 0\n",
    "\n",
    "    #Exports\n",
    "    try:\n",
    "        res['ExportNb'] = len(pe.DIRECTORY_ENTRY_EXPORT.symbols)\n",
    "    except AttributeError:\n",
    "        # No export\n",
    "        res['ExportNb'] = 0\n",
    "    \n",
    "    #Resources\n",
    "    resources= get_resources(pe)\n",
    "    res['ResourcesNb'] = len(resources)\n",
    "    \n",
    "    if len(resources)> 0:\n",
    "        entropy = map(lambda x:x[0], resources)\n",
    "        entropy_list = list(entropy)\n",
    "        res['ResourcesMeanEntropy'] = sum(entropy)/float(len(entropy_list))\n",
    "        res['ResourcesMinEntropy'] = min(entropy_list)\n",
    "        res['ResourcesMaxEntropy'] = max(entropy_list)\n",
    "        \n",
    "        sizes = map(lambda x:x[1], resources)\n",
    "        sizes_list = list(sizes)\n",
    "        res['ResourcesMeanSize'] = sum(sizes)/float(len(sizes_list))\n",
    "        res['ResourcesMinSize'] = min(sizes_list)\n",
    "        res['ResourcesMaxSize'] = max(sizes_list)\n",
    "    else:\n",
    "        res['ResourcesNb'] = 0\n",
    "        res['ResourcesMeanEntropy'] = 0\n",
    "        res['ResourcesMinEntropy'] = 0\n",
    "        res['ResourcesMaxEntropy'] = 0\n",
    "        res['ResourcesMeanSize'] = 0\n",
    "        res['ResourcesMinSize'] = 0\n",
    "        res['ResourcesMaxSize'] = 0\n",
    "\n",
    "    # Load configuration size\n",
    "    try:\n",
    "        res['LoadConfigurationSize'] = pe.DIRECTORY_ENTRY_LOAD_CONFIG.struct.Size\n",
    "    except AttributeError:\n",
    "        res['LoadConfigurationSize'] = 0\n",
    "\n",
    "\n",
    "    # Version configuration size\n",
    "    try:\n",
    "        version_infos = get_version_info(pe)\n",
    "        res['VersionInformationSize'] = len(version_infos.keys())\n",
    "    except AttributeError:\n",
    "        res['VersionInformationSize'] = 0\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
